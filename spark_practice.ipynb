{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession, types\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"test\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-N55KJK6U:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1073f5f7880>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data schema\n",
    "\n",
    "import pandas as pd\n",
    "df_pandas = pd.read_csv(\"./fhv_tripdata_2019-10.csv/fhv_tripdata_2019-10.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\Python38\\lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "c:\\Users\\ASUS\\Python38\\lib\\site-packages\\pyspark\\sql\\pandas\\conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropOff_datetime', StringType(), True), StructField('PUlocationID', DoubleType(), True), StructField('DOlocationID', DoubleType(), True), StructField('SR_Flag', DoubleType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_pandas.head()).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType(\n",
    "    [types.StructField('dispatching_base_num', types.StringType(), True), \n",
    "    types.StructField('pickup_datetime', types.StringType(), True), \n",
    "    types.StructField('dropOff_datetime', types.StringType(), True), \n",
    "    types.StructField('PUlocationID',types.IntegerType(), True), \n",
    "    types.StructField('DOlocationID', types.IntegerType(), True), \n",
    "    types.StructField('SR_Flag', types.StringType(), True), \n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file\n",
    "df = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .schema(schema)\\\n",
    "    .csv(\"./fhv_tripdata_2019-10.csv/fhv_tripdata_2019-10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B00009|2019-10-01 00:23:00|2019-10-01 00:35:00|         264|         264|   null|                B00009|\n",
      "|              B00013|2019-10-01 00:11:29|2019-10-01 00:13:22|         264|         264|   null|                B00013|\n",
      "|              B00014|2019-10-01 00:11:43|2019-10-01 00:37:20|         264|         264|   null|                B00014|\n",
      "|              B00014|2019-10-01 00:56:29|2019-10-01 00:57:47|         264|         264|   null|                B00014|\n",
      "|              B00014|2019-10-01 00:23:09|2019-10-01 00:28:27|         264|         264|   null|                B00014|\n",
      "|     B00021         |2019-10-01 00:00:48|2019-10-01 00:07:12|         129|         129|   null|       B00021         |\n",
      "|     B00021         |2019-10-01 00:47:23|2019-10-01 00:53:25|          57|          57|   null|       B00021         |\n",
      "|     B00021         |2019-10-01 00:10:06|2019-10-01 00:19:50|         173|         173|   null|       B00021         |\n",
      "|     B00021         |2019-10-01 00:51:37|2019-10-01 01:06:14|         226|         226|   null|       B00021         |\n",
      "|     B00021         |2019-10-01 00:28:23|2019-10-01 00:34:33|          56|          56|   null|       B00021         |\n",
      "|     B00021         |2019-10-01 00:31:17|2019-10-01 00:51:52|          82|          82|   null|       B00021         |\n",
      "|              B00037|2019-10-01 00:07:41|2019-10-01 00:15:23|         264|          71|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:13:38|2019-10-01 00:25:51|         264|          39|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:42:40|2019-10-01 00:53:47|         264|         188|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:58:46|2019-10-01 01:10:11|         264|          91|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:09:49|2019-10-01 00:14:37|         264|          71|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:22:35|2019-10-01 00:36:53|         264|          35|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:54:27|2019-10-01 01:03:37|         264|          61|   null|                B00037|\n",
      "|              B00037|2019-10-01 00:08:12|2019-10-01 00:28:47|         264|         198|   null|                B00037|\n",
      "|              B00053|2019-10-01 00:05:24|2019-10-01 00:53:03|         264|         264|   null|                  #N/A|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create partition table\n",
    "df = df.repartition(6)\n",
    "df.write.parquet(\"fhvhv/2019/10/\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read from partition\n",
    "df = spark.read.parquet(\"fhvhv/2019/10/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df\\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime))\\\n",
    "    .withColumn('dropoff_date', F.to_date(df.dropOff_datetime))\\\n",
    "    .select('pickup_date', 'dropoff_date', 'PULocationID', 'DOLocationID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+------------+------------+\n",
      "|pickup_date|dropoff_date|PULocationID|DOLocationID|\n",
      "+-----------+------------+------------+------------+\n",
      "| 2019-10-02|  2019-10-02|         264|         264|\n",
      "| 2019-10-01|  2019-10-01|         264|         264|\n",
      "| 2019-10-02|  2019-10-02|          42|         243|\n",
      "| 2019-10-02|  2019-10-02|         264|          70|\n",
      "| 2019-10-03|  2019-10-03|         264|         264|\n",
      "| 2019-10-02|  2019-10-02|         162|         265|\n",
      "| 2019-10-02|  2019-10-02|         264|         126|\n",
      "| 2019-10-02|  2019-10-02|         264|           3|\n",
      "| 2019-10-01|  2019-10-01|         264|         221|\n",
      "| 2019-10-01|  2019-10-01|         264|         254|\n",
      "| 2019-10-02|  2019-10-02|         264|          75|\n",
      "| 2019-10-01|  2019-10-01|         264|         264|\n",
      "| 2019-10-02|  2019-10-02|         264|          91|\n",
      "| 2019-10-01|  2019-10-01|         264|          18|\n",
      "| 2019-10-01|  2019-10-01|         264|         173|\n",
      "| 2019-10-03|  2019-10-03|         264|         264|\n",
      "| 2019-10-01|  2019-10-01|         264|         264|\n",
      "| 2019-10-02|  2019-10-02|         264|         258|\n",
      "| 2019-10-02|  2019-10-02|         264|         245|\n",
      "| 2019-10-03|  2019-10-03|         134|         197|\n",
      "+-----------+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count records on 15th October"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62610"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_df\\\n",
    "    .where(F.col(\"pickup_date\")==\"2019-10-15\")\\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B03201|2019-10-02 06:50:00|2019-10-02 08:08:00|         264|         264|   null|                B02867|\n",
      "|              B01129|2019-10-01 09:54:00|2019-10-01 10:09:00|         264|         264|   null|                B01129|\n",
      "|              B03142|2019-10-02 09:10:00|2019-10-02 09:37:45|          42|         243|   null|                B02884|\n",
      "|              B01381|2019-10-02 05:26:55|2019-10-02 05:34:34|         264|          70|   null|                B01381|\n",
      "|              B02285|2019-10-03 07:30:00|2019-10-03 09:46:00|         264|         264|   null|                B02285|\n",
      "|              B02715|2019-10-02 20:37:38|2019-10-02 21:15:11|         162|         265|   null|                B02866|\n",
      "|              B02509|2019-10-02 10:24:45|2019-10-02 10:40:03|         264|         126|   null|                B02682|\n",
      "|              B03016|2019-10-02 12:13:52|2019-10-02 12:21:08|         264|           3|   null|                B02878|\n",
      "|              B03139|2019-10-01 08:00:18|2019-10-01 09:00:41|         264|         221|   null|                B03139|\n",
      "|              B03016|2019-10-01 04:25:05|2019-10-01 04:32:51|         264|         254|   null|                B03016|\n",
      "|              B00937|2019-10-02 07:18:00|2019-10-02 07:39:20|         264|          75|   null|                B00937|\n",
      "|              B01979|2019-10-01 16:32:00|2019-10-01 16:52:00|         264|         264|   null|                B01979|\n",
      "|              B00536|2019-10-02 14:05:12|2019-10-02 14:09:20|         264|          91|   null|                B00536|\n",
      "|              B01338|2019-10-01 15:44:40|2019-10-01 15:47:40|         264|          18|   null|                B01338|\n",
      "|              B01626|2019-10-01 10:52:40|2019-10-01 11:20:18|         264|         173|   null|                B01626|\n",
      "|              B01710|2019-10-03 08:06:13|2019-10-03 09:17:05|         264|         264|   null|                B01710|\n",
      "|              B02248|2019-10-01 07:13:12|2019-10-01 08:10:12|         264|         264|   null|                B02248|\n",
      "|              B01553|2019-10-02 13:17:15|2019-10-02 13:20:19|         264|         258|   null|                B01553|\n",
      "|              B03139|2019-10-02 14:00:17|2019-10-02 14:30:11|         264|         245|   null|                B03139|\n",
      "|              B00653|2019-10-03 10:04:00|2019-10-03 11:00:00|         134|         197|   null|                B00653|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The longest trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string columns to timestamp columns\n",
    "df = df.withColumn(\"pickup_time\", F.col(\"pickup_datetime\").cast(\"timestamp\"))\n",
    "df = df.withColumn(\"dropoff_time\", F.col(\"dropoff_datetime\").cast(\"timestamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the duration column\n",
    "df = df.withColumn(\"duration\", (F.col(\"dropoff_time\").cast(\"long\") - F.col(\"pickup_time\").cast(\"long\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest trip: 631152.5 hours\n"
     ]
    }
   ],
   "source": [
    "# Find the row with the maximum duration\n",
    "max_duration_row = df.agg((F.max(\"duration\") / 3600).alias('longest_trip_hour'))\n",
    "print(f\"longest trip: {max_duration_row.collect()[0]['longest_trip_hour']} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least frequent pickup location zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zone = spark.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .csv(\"./taxi_zone_lookup.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zone.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_join_df = df.join(df_zone, df['PUlocationID'] == df_zone['LocationID'], \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-------------------+-------------------+--------+----------+---------+--------------------+------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|        pickup_time|       dropoff_time|duration|LocationID|  Borough|                Zone|service_zone|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-------------------+-------------------+--------+----------+---------+--------------------+------------+\n",
      "|              B03201|2019-10-02 06:50:00|2019-10-02 08:08:00|         264|         264|   null|                B02867|2019-10-02 06:50:00|2019-10-02 08:08:00|    4680|       264|  Unknown|                  NV|         N/A|\n",
      "|              B01129|2019-10-01 09:54:00|2019-10-01 10:09:00|         264|         264|   null|                B01129|2019-10-01 09:54:00|2019-10-01 10:09:00|     900|       264|  Unknown|                  NV|         N/A|\n",
      "|              B03142|2019-10-02 09:10:00|2019-10-02 09:37:45|          42|         243|   null|                B02884|2019-10-02 09:10:00|2019-10-02 09:37:45|    1665|        42|Manhattan|Central Harlem North|   Boro Zone|\n",
      "|              B01381|2019-10-02 05:26:55|2019-10-02 05:34:34|         264|          70|   null|                B01381|2019-10-02 05:26:55|2019-10-02 05:34:34|     459|       264|  Unknown|                  NV|         N/A|\n",
      "|              B02285|2019-10-03 07:30:00|2019-10-03 09:46:00|         264|         264|   null|                B02285|2019-10-03 07:30:00|2019-10-03 09:46:00|    8160|       264|  Unknown|                  NV|         N/A|\n",
      "|              B02715|2019-10-02 20:37:38|2019-10-02 21:15:11|         162|         265|   null|                B02866|2019-10-02 20:37:38|2019-10-02 21:15:11|    2253|       162|Manhattan|        Midtown East| Yellow Zone|\n",
      "|              B02509|2019-10-02 10:24:45|2019-10-02 10:40:03|         264|         126|   null|                B02682|2019-10-02 10:24:45|2019-10-02 10:40:03|     918|       264|  Unknown|                  NV|         N/A|\n",
      "|              B03016|2019-10-02 12:13:52|2019-10-02 12:21:08|         264|           3|   null|                B02878|2019-10-02 12:13:52|2019-10-02 12:21:08|     436|       264|  Unknown|                  NV|         N/A|\n",
      "|              B03139|2019-10-01 08:00:18|2019-10-01 09:00:41|         264|         221|   null|                B03139|2019-10-01 08:00:18|2019-10-01 09:00:41|    3623|       264|  Unknown|                  NV|         N/A|\n",
      "|              B03016|2019-10-01 04:25:05|2019-10-01 04:32:51|         264|         254|   null|                B03016|2019-10-01 04:25:05|2019-10-01 04:32:51|     466|       264|  Unknown|                  NV|         N/A|\n",
      "|              B00937|2019-10-02 07:18:00|2019-10-02 07:39:20|         264|          75|   null|                B00937|2019-10-02 07:18:00|2019-10-02 07:39:20|    1280|       264|  Unknown|                  NV|         N/A|\n",
      "|              B01979|2019-10-01 16:32:00|2019-10-01 16:52:00|         264|         264|   null|                B01979|2019-10-01 16:32:00|2019-10-01 16:52:00|    1200|       264|  Unknown|                  NV|         N/A|\n",
      "|              B00536|2019-10-02 14:05:12|2019-10-02 14:09:20|         264|          91|   null|                B00536|2019-10-02 14:05:12|2019-10-02 14:09:20|     248|       264|  Unknown|                  NV|         N/A|\n",
      "|              B01338|2019-10-01 15:44:40|2019-10-01 15:47:40|         264|          18|   null|                B01338|2019-10-01 15:44:40|2019-10-01 15:47:40|     180|       264|  Unknown|                  NV|         N/A|\n",
      "|              B01626|2019-10-01 10:52:40|2019-10-01 11:20:18|         264|         173|   null|                B01626|2019-10-01 10:52:40|2019-10-01 11:20:18|    1658|       264|  Unknown|                  NV|         N/A|\n",
      "|              B01710|2019-10-03 08:06:13|2019-10-03 09:17:05|         264|         264|   null|                B01710|2019-10-03 08:06:13|2019-10-03 09:17:05|    4252|       264|  Unknown|                  NV|         N/A|\n",
      "|              B02248|2019-10-01 07:13:12|2019-10-01 08:10:12|         264|         264|   null|                B02248|2019-10-01 07:13:12|2019-10-01 08:10:12|    3420|       264|  Unknown|                  NV|         N/A|\n",
      "|              B01553|2019-10-02 13:17:15|2019-10-02 13:20:19|         264|         258|   null|                B01553|2019-10-02 13:17:15|2019-10-02 13:20:19|     184|       264|  Unknown|                  NV|         N/A|\n",
      "|              B03139|2019-10-02 14:00:17|2019-10-02 14:30:11|         264|         245|   null|                B03139|2019-10-02 14:00:17|2019-10-02 14:30:11|    1794|       264|  Unknown|                  NV|         N/A|\n",
      "|              B00653|2019-10-03 10:04:00|2019-10-03 11:00:00|         134|         197|   null|                B00653|2019-10-03 10:04:00|2019-10-03 11:00:00|    3360|       134|   Queens|         Kew Gardens|   Boro Zone|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-------------------+-------------------+--------+----------+---------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_join_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = full_join_df\\\n",
    "    .groupBy(\"Zone\")\\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least pickup location: Jamaica Bay\n"
     ]
    }
   ],
   "source": [
    "least_PU_location = count_df\\\n",
    "    .orderBy(F.col(\"count\"))\\\n",
    "    .first()\n",
    "\n",
    "print(f\"least pickup location: {least_PU_location['Zone']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
